{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import notebook\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(str(Path().absolute().parent))\n",
    "\n",
    "from src.map_at_k import mapk, apk\n",
    "from src.negative_sampling import NegativeSampling\n",
    "import lightgbm as lgb\n",
    "# mac install lightgbm - https://www.geeksforgeeks.org/how-to-install-xgboost-and-lightgbm-on-macos/\n",
    "# mac M1 pip problem (can also solve lightgbm install) - https://stackoverflow.com/questions/68620927/installing-scipy-and-scikit-learn-on-apple-m1/70178471#70178471\n",
    "# mac M1 have to use conda to install pytorch () - https://betterprogramming.pub/how-to-install-pytorch-on-apple-m1-series-512b3ad9bc6\n",
    "# scipy early version cannot be install at mac M1 (e.g., scipy 1.6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notes\n",
    "\n",
    "* articles.csv, transactions_train.csv, customers.csv, sample_submission.csv are download from kaggle \\\n",
    "    https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data\n",
    "* user_features.parquet, item_features.parquet are create by notebook \\\n",
    "    hm_generate_advance_article_features.ipynb, hm_generate_advance_user_features.ipynb\n",
    "\"\"\"\n",
    "\n",
    "base_pth = Path().absolute().parent\n",
    "article_pth = base_pth/'datasets/articles.csv'\n",
    "transaction_pth = base_pth/'datasets/transactions_train.csv'\n",
    "customer_pth = base_pth/'datasets/customers.csv'\n",
    "submission_pth = base_pth/'datasets/sample_submission.csv'\n",
    "\n",
    "adv_user_feature_pth = base_pth/'datasets/user_features.parquet'\n",
    "adv_item_feature_pth = base_pth/'datasets/item_features.parquet'\n",
    "\n",
    "output_pth = base_pth/'output_data/submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user features\n",
    "user_features = pd.read_parquet(adv_user_feature_pth)\n",
    "# str to int\n",
    "user_features[['club_member_status', 'fashion_news_frequency']] = (\n",
    "    user_features[['club_member_status', 'fashion_news_frequency']]\n",
    "    .apply(lambda x: pd.factorize(x)[0])\n",
    ").astype('int8')\n",
    "user_features = user_features.reset_index()\n",
    "\n",
    "\n",
    "# article features\n",
    "article_df = pd.read_csv(article_pth)\n",
    "article_df['article_id'] = '0' + article_df['article_id'].astype(str)\n",
    "\n",
    "\n",
    "# item features\n",
    "item_features = pd.read_parquet(adv_item_feature_pth)\n",
    "item_features = item_features.reset_index()\n",
    "item_features['article_id'] = '0' + item_features['article_id'].astype(str)\n",
    "\n",
    "\n",
    "# customer features\n",
    "customer_df = pd.read_csv(customer_pth)\n",
    "# customer_df['age_bins'] = pd.cut(customer_df['age'], [-1, 19, 29, 39, 49, 69, 119])\n",
    "# customer_df['age_bins'] = customer_df['age_bins'].astype(str)\n",
    "\n",
    "\n",
    "# transaction features\n",
    "transaction_df = pd.read_csv(transaction_pth)\n",
    "transaction_df['t_dat'] = pd.to_datetime(transaction_df['t_dat'])\n",
    "transaction_df['article_id'] = '0' + transaction_df['article_id'].astype(str)\n",
    "# week from 104 - 0 (close - far)\n",
    "transaction_df['week'] = 104 - (transaction_df.t_dat.max() - transaction_df.t_dat).dt.days // 7\n",
    "\n",
    "\n",
    "\n",
    "# submission data\n",
    "sub = pd.read_csv(\n",
    "    submission_pth,\n",
    "    usecols=['customer_id'],\n",
    "    dtype={'customer_id': 'string'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "neg_sampling = NegativeSampling(\n",
    "    transaction_df=transaction_df, train_inteval=10\n",
    ")\n",
    "data = neg_sampling.create_data_with_neg_sample(\n",
    "    extra_user_features=user_features,\n",
    "    extra_item_features=item_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_week = neg_sampling.valid_week\n",
    "\n",
    "train = data[data.week != valid_week]\n",
    "valid = data[data.week==valid_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()\n",
    "\n",
    "train_X = train.drop(columns=['purchased', 't_dat', 'price', 'sales_channel_id', 'customer_id', 'article_id', 'week'])\n",
    "train_y = train['purchased']\n",
    "valid_X = valid.drop(columns=['purchased', 't_dat', 'price', 'sales_channel_id', 'customer_id', 'article_id', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認正負樣本比例\n",
    "train.groupby('purchased').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "# 注意: 這邊的 train 需要按照組別順序來給\n",
    "train_baskets = train.groupby(\n",
    "    ['week', 'customer_id']\n",
    ")['article_id'].count().values\n",
    "\n",
    "ranker = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=100,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")\n",
    "ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備推薦商品, 預測值\n",
    "valid['preds'] = ranker.predict(valid_X)\n",
    "\n",
    "c_id2predicted_article_ids = (\n",
    "    valid\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False)\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    ")\n",
    "\n",
    "bestsellers_last_week = \\\n",
    "    neg_sampling.bestsellers_previous_week[\n",
    "        neg_sampling.bestsellers_previous_week.week == neg_sampling.bestsellers_previous_week.week.max()\n",
    "    ]['article_id'].tolist()\n",
    "\n",
    "\n",
    "# create submission (valid prediction)\n",
    "preds = []\n",
    "for c_id in sub.customer_id:\n",
    "    pred = c_id2predicted_article_ids.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])\n",
    "\n",
    "preds = [' '.join([str(p) for p in ps]) for ps in preds]\n",
    "sub['prediction'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## measure map@12 at valid\n",
    "valid_ground_true = neg_sampling.valid_trans.groupby(\n",
    "    'customer_id', as_index=False\n",
    ").agg(ground_true=('article_id', list))\n",
    "\n",
    "measure_df = sub[['customer_id', 'prediction']]\n",
    "measure_df = measure_df.merge(valid_ground_true, on='customer_id', how='inner')\n",
    "measure_df['prediction'] = [pred.split(' ') for pred in list(measure_df['prediction'].values)]\n",
    "\n",
    "mapk_value = mapk(measure_df, pred_col='prediction', ground_true_col='ground_true', k=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapk_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hm_rec_competition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08b6713e588fa6908b7e8d6146c93eb3aac50229c527a3756f585dd9e5927f1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
